2025-05-27 22:10:15,955 DeMo INFO: Saving model in the path :./RGBNT100-DeMo/multimodelse_diversity_weight6_deform_20250527_221012
2025-05-27 22:10:15,955 DeMo INFO: Namespace(config_file='configs/RGBNT100/DeMo.yml', fea_cft=0, local_rank=0, opts=['OUTPUT_DIR', './RGBNT100-DeMo/multimodelse_diversity_weight6_deform_20250527_221012'])
2025-05-27 22:10:15,955 DeMo INFO: Loaded configuration file configs/RGBNT100/DeMo.yml
2025-05-27 22:10:15,955 DeMo INFO: 
MODEL:
  TRANSFORMER_TYPE: 'ViT-B-16'
  STRIDE_SIZE: [ 16, 16 ]
  SIE_CAMERA: True
  DIRECT: 0
  SIE_COE: 1.0
  ID_LOSS_WEIGHT: 0.25
  TRIPLET_LOSS_WEIGHT: 1.0
  GLOBAL_LOCAL: True
  HDM: True
  ATM: True
  HEAD: 8
  CENGJIFUSION: True

INPUT:
  SIZE_TRAIN: [ 128, 256 ]
  SIZE_TEST: [ 128, 256 ]
  PROB: 0.5 # random horizontal flip
  RE_PROB: 0.5 # random erasing
  PADDING: 10

DATALOADER:
  SAMPLER: 'softmax_triplet'
  NUM_INSTANCE: 16
  NUM_WORKERS: 14

DATASETS:
  NAMES: ('RGBNT100')
  ROOT_DIR: '..'

SOLVER:
  BASE_LR: 0.00035
  WARMUP_ITERS: 5
  MAX_EPOCHS: 30
  OPTIMIZER_NAME: 'Adam'
  GAMMA: 0.1
  IMS_PER_BATCH: 64
  EVAL_PERIOD: 1
  SEED: 1111

TEST:
  IMS_PER_BATCH: 128
  RE_RANKING: 'no'
  WEIGHT: ''
  NECK_FEAT: 'before'
  FEAT_NORM: 'yes'
  MISS: "nothing"

OUTPUT_DIR: '..'




2025-05-27 22:10:15,956 DeMo INFO: Running with config:
DATALOADER:
  NUM_INSTANCE: 16
  NUM_WORKERS: 14
  SAMPLER: softmax_triplet
DATASETS:
  NAMES: RGBNT100
  ROOT_DIR: ..
INPUT:
  PADDING: 10
  PIXEL_MEAN: [0.5, 0.5, 0.5]
  PIXEL_STD: [0.5, 0.5, 0.5]
  PROB: 0.5
  RE_PROB: 0.5
  SIZE_TEST: [128, 256]
  SIZE_TRAIN: [128, 256]
MODEL:
  ADAPTER: False
  ATM: True
  ATT_DROP_RATE: 0.0
  CENGJIFUSION: True
  DEVICE: cuda
  DEVICE_ID: 0
  DIRECT: 0
  DIST_TRAIN: False
  DROP_OUT: 0.0
  DROP_PATH: 0.1
  FROZEN: False
  GLOBAL_LOCAL: True
  HDM: True
  HEAD: 8
  ID_LOSS_TYPE: softmax
  ID_LOSS_WEIGHT: 0.25
  IF_LABELSMOOTH: on
  IF_WITH_CENTER: no
  METRIC_LOSS_TYPE: triplet
  NAME: DeMo
  NECK: bnneck
  NO_MARGIN: True
  PRETRAIN_PATH_T: /path/to/your/vitb_16_224_21k.pth
  PROMPT: False
  SIE_CAMERA: True
  SIE_COE: 1.0
  SIE_VIEW: False
  STRIDE_SIZE: [16, 16]
  TRANSFORMER_TYPE: ViT-B-16
  TRIPLET_LOSS_WEIGHT: 1.0
OUTPUT_DIR: ./RGBNT100-DeMo/multimodelse_diversity_weight6_deform_20250527_221012
SOLVER:
  BASE_LR: 0.00035
  BIAS_LR_FACTOR: 2
  CENTER_LOSS_WEIGHT: 0.0005
  CENTER_LR: 0.5
  CHECKPOINT_PERIOD: 60
  CLUSTER_MARGIN: 0.3
  COSINE_MARGIN: 0.5
  COSINE_SCALE: 30
  EVAL_PERIOD: 1
  GAMMA: 0.1
  IMS_PER_BATCH: 64
  LARGE_FC_LR: False
  LOG_PERIOD: 10
  MARGIN: 0.3
  MAX_EPOCHS: 30
  MOMENTUM: 0.9
  OPTIMIZER_NAME: Adam
  RANGE_ALPHA: 0
  RANGE_BETA: 1
  RANGE_K: 2
  RANGE_LOSS_WEIGHT: 1
  RANGE_MARGIN: 0.3
  SEED: 1111
  STEPS: (40, 70)
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 5
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
TEST:
  FEAT: 0
  FEAT_NORM: yes
  IMS_PER_BATCH: 128
  MISS: nothing
  NECK_FEAT: before
  RE_RANKING: no
  WEIGHT: 
=> RGB_IR loaded
Dataset statistics:
  ----------------------------------------
  subset   | # ids | # images | # cameras
  ----------------------------------------
  train    |    50 |     8675 |         8
  query    |    50 |     1715 |         8
  gallery  |    50 |     8575 |         8
  ----------------------------------------
data is ready
cengjifusion: True
rwkvbackbone: False
using Transformer_type: ViT-B-16 as a backbone
simplegate: False
Resized position embedding: %s to %s torch.Size([197, 768]) torch.Size([129, 768])
Position embedding resize to height:8 width: 16
Successfully load ckpt!
_IncompatibleKeys(missing_keys=['visual.triple_dff.fc_atten1.0.weight', 'visual.triple_dff.fc_atten1.1.weight', 'visual.triple_dff.fc_atten1.1.bias', 'visual.triple_dff.fc_atten2.0.weight', 'visual.triple_dff.fc_atten2.1.weight', 'visual.triple_dff.fc_atten2.1.bias', 'visual.triple_dff.fc_atten4.0.weight', 'visual.triple_dff.fc_atten4.1.weight', 'visual.triple_dff.fc_atten4.1.bias', 'visual.triple_dff.input_weight_net.0.weight', 'visual.triple_dff.input_weight_net.0.bias', 'visual.triple_dff.input_weight_net.2.weight', 'visual.triple_dff.input_weight_net.2.bias', 'visual.triple_dff.gate_fc.0.weight', 'visual.triple_dff.gate_enhancement.0.weight', 'visual.triple_dff.gate_enhancement.0.bias', 'visual.triple_dff.fc_redu.0.weight', 'visual.triple_dff.fc_redu.1.weight', 'visual.triple_dff.fc_redu.1.bias', 'visual.triple_dff.residual_fc1.0.weight', 'visual.triple_dff.residual_fc1.1.weight', 'visual.triple_dff.residual_fc1.1.bias', 'visual.triple_dff.residual_fc2.0.weight', 'visual.triple_dff.residual_fc2.1.weight', 'visual.triple_dff.residual_fc2.1.bias', 'visual.triple_dff.residual_fc3.0.weight', 'visual.triple_dff.residual_fc3.1.weight', 'visual.triple_dff.residual_fc3.1.bias', 'visual.triple_dff.residual_fusion.0.weight', 'visual.triple_dff.residual_fusion.1.weight', 'visual.triple_dff.residual_fusion.1.bias', 'visual.triple_dff.fc1.weight', 'visual.triple_dff.fc1.bias', 'visual.triple_dff.fc2.weight', 'visual.triple_dff.fc2.bias', 'visual.triple_dff.fc3.weight', 'visual.triple_dff.fc3.bias', 'visual.triple_dff.attention_fusion.0.weight', 'visual.triple_dff.attention_fusion.0.bias', 'visual.quad_dffs.stage1_triple_dff.fc_atten1.0.weight', 'visual.quad_dffs.stage1_triple_dff.fc_atten1.1.weight', 'visual.quad_dffs.stage1_triple_dff.fc_atten1.1.bias', 'visual.quad_dffs.stage1_triple_dff.fc_atten2.0.weight', 'visual.quad_dffs.stage1_triple_dff.fc_atten2.1.weight', 'visual.quad_dffs.stage1_triple_dff.fc_atten2.1.bias', 'visual.quad_dffs.stage1_triple_dff.fc_atten4.0.weight', 'visual.quad_dffs.stage1_triple_dff.fc_atten4.1.weight', 'visual.quad_dffs.stage1_triple_dff.fc_atten4.1.bias', 'visual.quad_dffs.stage1_triple_dff.input_weight_net.0.weight', 'visual.quad_dffs.stage1_triple_dff.input_weight_net.0.bias', 'visual.quad_dffs.stage1_triple_dff.input_weight_net.2.weight', 'visual.quad_dffs.stage1_triple_dff.input_weight_net.2.bias', 'visual.quad_dffs.stage1_triple_dff.gate_fc.0.weight', 'visual.quad_dffs.stage1_triple_dff.gate_enhancement.0.weight', 'visual.quad_dffs.stage1_triple_dff.gate_enhancement.0.bias', 'visual.quad_dffs.stage1_triple_dff.fc_redu.0.weight', 'visual.quad_dffs.stage1_triple_dff.fc_redu.1.weight', 'visual.quad_dffs.stage1_triple_dff.fc_redu.1.bias', 'visual.quad_dffs.stage1_triple_dff.residual_fc1.0.weight', 'visual.quad_dffs.stage1_triple_dff.residual_fc1.1.weight', 'visual.quad_dffs.stage1_triple_dff.residual_fc1.1.bias', 'visual.quad_dffs.stage1_triple_dff.residual_fc2.0.weight', 'visual.quad_dffs.stage1_triple_dff.residual_fc2.1.weight', 'visual.quad_dffs.stage1_triple_dff.residual_fc2.1.bias', 'visual.quad_dffs.stage1_triple_dff.residual_fc3.0.weight', 'visual.quad_dffs.stage1_triple_dff.residual_fc3.1.weight', 'visual.quad_dffs.stage1_triple_dff.residual_fc3.1.bias', 'visual.quad_dffs.stage1_triple_dff.residual_fusion.0.weight', 'visual.quad_dffs.stage1_triple_dff.residual_fusion.1.weight', 'visual.quad_dffs.stage1_triple_dff.residual_fusion.1.bias', 'visual.quad_dffs.stage1_triple_dff.fc1.weight', 'visual.quad_dffs.stage1_triple_dff.fc1.bias', 'visual.quad_dffs.stage1_triple_dff.fc2.weight', 'visual.quad_dffs.stage1_triple_dff.fc2.bias', 'visual.quad_dffs.stage1_triple_dff.fc3.weight', 'visual.quad_dffs.stage1_triple_dff.fc3.bias', 'visual.quad_dffs.stage1_triple_dff.attention_fusion.0.weight', 'visual.quad_dffs.stage1_triple_dff.attention_fusion.0.bias', 'visual.quad_dffs.stage1_enhancement.0.weight', 'visual.quad_dffs.stage1_enhancement.0.bias', 'visual.quad_dffs.stage1_enhancement.1.weight', 'visual.quad_dffs.stage1_enhancement.1.bias', 'visual.quad_dffs.stage1_enhancement.3.weight', 'visual.quad_dffs.stage1_enhancement.3.bias', 'visual.quad_dffs.stage1_enhancement.5.weight', 'visual.quad_dffs.stage1_enhancement.5.bias', 'visual.quad_dffs.input4_preprocessing.0.weight', 'visual.quad_dffs.input4_preprocessing.0.bias', 'visual.quad_dffs.input4_preprocessing.1.weight', 'visual.quad_dffs.input4_preprocessing.1.bias', 'visual.quad_dffs.input4_preprocessing.3.weight', 'visual.quad_dffs.input4_preprocessing.3.bias', 'visual.quad_dffs.input4_preprocessing.4.weight', 'visual.quad_dffs.input4_preprocessing.4.bias', 'visual.quad_dffs.cross_stage_attention.0.weight', 'visual.quad_dffs.cross_stage_attention.0.bias', 'visual.quad_dffs.cross_stage_attention.2.weight', 'visual.quad_dffs.cross_stage_attention.2.bias', 'visual.quad_dffs.adaptive_fusion_weight.0.weight', 'visual.quad_dffs.adaptive_fusion_weight.0.bias', 'visual.quad_dffs.adaptive_fusion_weight.2.weight', 'visual.quad_dffs.adaptive_fusion_weight.2.bias', 'visual.quad_dffs.stage2_dff.fc_atten1.0.weight', 'visual.quad_dffs.stage2_dff.fc_atten2.0.weight', 'visual.quad_dffs.stage2_dff.fc_atten3.0.weight', 'visual.quad_dffs.stage2_dff.gate_fc.0.weight', 'visual.quad_dffs.stage2_dff.fc_redu.weight', 'visual.quad_dffs.stage2_dff.residual_fc.weight', 'visual.quad_dffs.stage2_dff.fc1.weight', 'visual.quad_dffs.stage2_dff.fc1.bias', 'visual.quad_dffs.stage2_dff.fc2.weight', 'visual.quad_dffs.stage2_dff.fc2.bias', 'visual.quad_dffs.memory_input1.weight', 'visual.quad_dffs.memory_input4.weight', 'visual.quad_dffs.memory_fusion.0.weight', 'visual.quad_dffs.memory_fusion.1.weight', 'visual.quad_dffs.memory_fusion.1.bias', 'visual.quad_dffs.global_context.0.weight', 'visual.quad_dffs.global_context.0.bias', 'visual.quad_dffs.global_context.2.weight', 'visual.quad_dffs.global_context.2.bias', 'visual.quad_dffs.final_refinement.0.weight', 'visual.quad_dffs.final_refinement.0.bias', 'visual.quad_dffs.final_refinement.1.weight', 'visual.quad_dffs.final_refinement.1.bias', 'visual.quad_dffs.final_refinement.3.weight', 'visual.quad_dffs.final_refinement.3.bias', 'visual.quad_dffs.final_refinement.4.weight', 'visual.quad_dffs.final_refinement.4.bias', 'visual.gated_enhancement.rgb_gating.residual_weight', 'visual.gated_enhancement.rgb_gating.cross_modal_attention.q_proj.weight', 'visual.gated_enhancement.rgb_gating.cross_modal_attention.k_proj.weight', 'visual.gated_enhancement.rgb_gating.cross_modal_attention.v_proj.weight', 'visual.gated_enhancement.rgb_gating.cross_modal_attention.out_proj.weight', 'visual.gated_enhancement.rgb_gating.cross_modal_attention.out_proj.bias', 'visual.gated_enhancement.rgb_gating.channel_gate.0.weight', 'visual.gated_enhancement.rgb_gating.channel_gate.0.bias', 'visual.gated_enhancement.rgb_gating.channel_gate.2.weight', 'visual.gated_enhancement.rgb_gating.channel_gate.2.bias', 'visual.gated_enhancement.rgb_gating.spatial_gate.0.weight', 'visual.gated_enhancement.rgb_gating.spatial_gate.0.bias', 'visual.gated_enhancement.rgb_gating.spatial_gate.2.weight', 'visual.gated_enhancement.rgb_gating.spatial_gate.2.bias', 'visual.gated_enhancement.rgb_gating.feature_fusion.0.weight', 'visual.gated_enhancement.rgb_gating.feature_fusion.0.bias', 'visual.gated_enhancement.rgb_gating.feature_fusion.1.weight', 'visual.gated_enhancement.rgb_gating.feature_fusion.1.bias', 'visual.gated_enhancement.rgb_gating.feature_fusion.3.weight', 'visual.gated_enhancement.rgb_gating.feature_fusion.3.bias', 'visual.gated_enhancement.rgb_gating.feature_fusion.4.weight', 'visual.gated_enhancement.rgb_gating.feature_fusion.4.bias', 'visual.gated_enhancement.rgb_gating.adaptive_weight.0.weight', 'visual.gated_enhancement.rgb_gating.adaptive_weight.0.bias', 'visual.gated_enhancement.rgb_gating.adaptive_weight.2.weight', 'visual.gated_enhancement.rgb_gating.adaptive_weight.2.bias', 'visual.gated_enhancement.nir_gating.residual_weight', 'visual.gated_enhancement.nir_gating.cross_modal_attention.q_proj.weight', 'visual.gated_enhancement.nir_gating.cross_modal_attention.k_proj.weight', 'visual.gated_enhancement.nir_gating.cross_modal_attention.v_proj.weight', 'visual.gated_enhancement.nir_gating.cross_modal_attention.out_proj.weight', 'visual.gated_enhancement.nir_gating.cross_modal_attention.out_proj.bias', 'visual.gated_enhancement.nir_gating.channel_gate.0.weight', 'visual.gated_enhancement.nir_gating.channel_gate.0.bias', 'visual.gated_enhancement.nir_gating.channel_gate.2.weight', 'visual.gated_enhancement.nir_gating.channel_gate.2.bias', 'visual.gated_enhancement.nir_gating.spatial_gate.0.weight', 'visual.gated_enhancement.nir_gating.spatial_gate.0.bias', 'visual.gated_enhancement.nir_gating.spatial_gate.2.weight', 'visual.gated_enhancement.nir_gating.spatial_gate.2.bias', 'visual.gated_enhancement.nir_gating.feature_fusion.0.weight', 'visual.gated_enhancement.nir_gating.feature_fusion.0.bias', 'visual.gated_enhancement.nir_gating.feature_fusion.1.weight', 'visual.gated_enhancement.nir_gating.feature_fusion.1.bias', 'visual.gated_enhancement.nir_gating.feature_fusion.3.weight', 'visual.gated_enhancement.nir_gating.feature_fusion.3.bias', 'visual.gated_enhancement.nir_gating.feature_fusion.4.weight', 'visual.gated_enhancement.nir_gating.feature_fusion.4.bias', 'visual.gated_enhancement.nir_gating.adaptive_weight.0.weight', 'visual.gated_enhancement.nir_gating.adaptive_weight.0.bias', 'visual.gated_enhancement.nir_gating.adaptive_weight.2.weight', 'visual.gated_enhancement.nir_gating.adaptive_weight.2.bias', 'visual.gated_enhancement.tir_gating.residual_weight', 'visual.gated_enhancement.tir_gating.cross_modal_attention.q_proj.weight', 'visual.gated_enhancement.tir_gating.cross_modal_attention.k_proj.weight', 'visual.gated_enhancement.tir_gating.cross_modal_attention.v_proj.weight', 'visual.gated_enhancement.tir_gating.cross_modal_attention.out_proj.weight', 'visual.gated_enhancement.tir_gating.cross_modal_attention.out_proj.bias', 'visual.gated_enhancement.tir_gating.channel_gate.0.weight', 'visual.gated_enhancement.tir_gating.channel_gate.0.bias', 'visual.gated_enhancement.tir_gating.channel_gate.2.weight', 'visual.gated_enhancement.tir_gating.channel_gate.2.bias', 'visual.gated_enhancement.tir_gating.spatial_gate.0.weight', 'visual.gated_enhancement.tir_gating.spatial_gate.0.bias', 'visual.gated_enhancement.tir_gating.spatial_gate.2.weight', 'visual.gated_enhancement.tir_gating.spatial_gate.2.bias', 'visual.gated_enhancement.tir_gating.feature_fusion.0.weight', 'visual.gated_enhancement.tir_gating.feature_fusion.0.bias', 'visual.gated_enhancement.tir_gating.feature_fusion.1.weight', 'visual.gated_enhancement.tir_gating.feature_fusion.1.bias', 'visual.gated_enhancement.tir_gating.feature_fusion.3.weight', 'visual.gated_enhancement.tir_gating.feature_fusion.3.bias', 'visual.gated_enhancement.tir_gating.feature_fusion.4.weight', 'visual.gated_enhancement.tir_gating.feature_fusion.4.bias', 'visual.gated_enhancement.tir_gating.adaptive_weight.0.weight', 'visual.gated_enhancement.tir_gating.adaptive_weight.0.bias', 'visual.gated_enhancement.tir_gating.adaptive_weight.2.weight', 'visual.gated_enhancement.tir_gating.adaptive_weight.2.bias', 'visual.gated_enhancement.global_coordination.interaction_net.0.weight', 'visual.gated_enhancement.global_coordination.interaction_net.0.bias', 'visual.gated_enhancement.global_coordination.interaction_net.1.weight', 'visual.gated_enhancement.global_coordination.interaction_net.1.bias', 'visual.gated_enhancement.global_coordination.interaction_net.3.weight', 'visual.gated_enhancement.global_coordination.interaction_net.3.bias', 'visual.gated_enhancement.global_coordination.interaction_net.4.weight', 'visual.gated_enhancement.global_coordination.interaction_net.4.bias', 'visual.gated_enhancement.global_coordination.balance_net.0.weight', 'visual.gated_enhancement.global_coordination.balance_net.0.bias', 'visual.gated_enhancement.global_coordination.balance_net.2.weight', 'visual.gated_enhancement.global_coordination.balance_net.2.bias', 'visual.gated_enhancement.global_coordination.global_gate.0.weight', 'visual.gated_enhancement.global_coordination.global_gate.0.bias', 'visual.gated_enhancement.global_coordination.global_gate.2.weight', 'visual.gated_enhancement.global_coordination.global_gate.2.bias'], unexpected_keys=[])
Loading pretrained model from CLIP
camera number is : 8
combineway: multimodelse
2025-05-27 22:10:24,570 DeMo INFO: combineway: multimodelse
UsingDiversity: True
===========Building DeMo===========
2025-05-27 22:10:24,608 DeMo INFO: DeMo(
  (BACKBONE): build_transformer_new(
    (base): VisionTransformer(
      (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (triple_dff): TripleInputDirectDFF(
        (avg_pool1): AdaptiveAvgPool1d(output_size=1)
        (avg_pool2): AdaptiveAvgPool1d(output_size=2)
        (avg_pool4): AdaptiveAvgPool1d(output_size=4)
        (fc_atten1): Sequential(
          (0): Linear(in_features=2304, out_features=2304, bias=False)
          (1): LayerNorm((2304,), eps=1e-05, elementwise_affine=True)
          (2): Sigmoid()
        )
        (fc_atten2): Sequential(
          (0): Linear(in_features=2304, out_features=2304, bias=False)
          (1): LayerNorm((2304,), eps=1e-05, elementwise_affine=True)
          (2): Sigmoid()
        )
        (fc_atten4): Sequential(
          (0): Linear(in_features=2304, out_features=2304, bias=False)
          (1): LayerNorm((2304,), eps=1e-05, elementwise_affine=True)
          (2): Sigmoid()
        )
        (input_weight_net): Sequential(
          (0): Linear(in_features=2304, out_features=768, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=768, out_features=3, bias=True)
          (3): Softmax(dim=-1)
        )
        (gate_fc): Sequential(
          (0): Linear(in_features=2304, out_features=2304, bias=False)
          (1): Sigmoid()
        )
        (gate_enhancement): Sequential(
          (0): Linear(in_features=2304, out_features=2304, bias=True)
          (1): Tanh()
        )
        (fc_redu): Sequential(
          (0): Linear(in_features=2304, out_features=768, bias=False)
          (1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
        )
        (residual_fc1): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=False)
          (1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (residual_fc2): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=False)
          (1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (residual_fc3): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=False)
          (1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (residual_fusion): Sequential(
          (0): Linear(in_features=2304, out_features=768, bias=False)
          (1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (fc1): Linear(in_features=768, out_features=1, bias=True)
        (fc2): Linear(in_features=768, out_features=1, bias=True)
        (fc3): Linear(in_features=768, out_features=1, bias=True)
        (attention_fusion): Sequential(
          (0): Linear(in_features=3, out_features=1, bias=True)
          (1): Sigmoid()
        )
      )
      (quad_dffs): QuadInputHierarchicalDFF(
        (stage1_triple_dff): TripleInputDirectDFF(
          (avg_pool1): AdaptiveAvgPool1d(output_size=1)
          (avg_pool2): AdaptiveAvgPool1d(output_size=2)
          (avg_pool4): AdaptiveAvgPool1d(output_size=4)
          (fc_atten1): Sequential(
            (0): Linear(in_features=2304, out_features=2304, bias=False)
            (1): LayerNorm((2304,), eps=1e-05, elementwise_affine=True)
            (2): Sigmoid()
          )
          (fc_atten2): Sequential(
            (0): Linear(in_features=2304, out_features=2304, bias=False)
            (1): LayerNorm((2304,), eps=1e-05, elementwise_affine=True)
            (2): Sigmoid()
          )
          (fc_atten4): Sequential(
            (0): Linear(in_features=2304, out_features=2304, bias=False)
            (1): LayerNorm((2304,), eps=1e-05, elementwise_affine=True)
            (2): Sigmoid()
          )
          (input_weight_net): Sequential(
            (0): Linear(in_features=2304, out_features=768, bias=True)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=768, out_features=3, bias=True)
            (3): Softmax(dim=-1)
          )
          (gate_fc): Sequential(
            (0): Linear(in_features=2304, out_features=2304, bias=False)
            (1): Sigmoid()
          )
          (gate_enhancement): Sequential(
            (0): Linear(in_features=2304, out_features=2304, bias=True)
            (1): Tanh()
          )
          (fc_redu): Sequential(
            (0): Linear(in_features=2304, out_features=768, bias=False)
            (1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (2): ReLU(inplace=True)
          )
          (residual_fc1): Sequential(
            (0): Linear(in_features=768, out_features=768, bias=False)
            (1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (residual_fc2): Sequential(
            (0): Linear(in_features=768, out_features=768, bias=False)
            (1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (residual_fc3): Sequential(
            (0): Linear(in_features=768, out_features=768, bias=False)
            (1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (residual_fusion): Sequential(
            (0): Linear(in_features=2304, out_features=768, bias=False)
            (1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (fc1): Linear(in_features=768, out_features=1, bias=True)
          (fc2): Linear(in_features=768, out_features=1, bias=True)
          (fc3): Linear(in_features=768, out_features=1, bias=True)
          (attention_fusion): Sequential(
            (0): Linear(in_features=3, out_features=1, bias=True)
            (1): Sigmoid()
          )
        )
        (stage1_enhancement): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=768, out_features=192, bias=True)
          (4): ReLU(inplace=True)
          (5): Linear(in_features=192, out_features=768, bias=True)
          (6): Sigmoid()
        )
        (input4_preprocessing): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=768, out_features=768, bias=True)
          (4): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (cross_stage_attention): Sequential(
          (0): Linear(in_features=768, out_features=96, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=96, out_features=768, bias=True)
          (3): Sigmoid()
        )
        (adaptive_fusion_weight): Sequential(
          (0): Linear(in_features=1536, out_features=192, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=192, out_features=2, bias=True)
          (3): Softmax(dim=-1)
        )
        (stage2_dff): InnovativeDFF(
          (avg_pool1): AdaptiveAvgPool1d(output_size=1)
          (avg_pool2): AdaptiveAvgPool1d(output_size=2)
          (avg_pool3): AdaptiveAvgPool1d(output_size=4)
          (fc_atten1): Sequential(
            (0): Linear(in_features=1536, out_features=1536, bias=False)
            (1): Sigmoid()
          )
          (fc_atten2): Sequential(
            (0): Linear(in_features=1536, out_features=1536, bias=False)
            (1): Sigmoid()
          )
          (fc_atten3): Sequential(
            (0): Linear(in_features=1536, out_features=1536, bias=False)
            (1): Sigmoid()
          )
          (gate_fc): Sequential(
            (0): Linear(in_features=1536, out_features=1536, bias=False)
            (1): Sigmoid()
          )
          (fc_redu): Linear(in_features=1536, out_features=768, bias=False)
          (residual_fc): Linear(in_features=768, out_features=768, bias=False)
          (fc1): Linear(in_features=768, out_features=1, bias=True)
          (fc2): Linear(in_features=768, out_features=1, bias=True)
          (nonlin): Sigmoid()
        )
        (memory_input1): Linear(in_features=768, out_features=768, bias=False)
        (memory_input4): Linear(in_features=768, out_features=768, bias=False)
        (memory_fusion): Sequential(
          (0): Linear(in_features=1536, out_features=768, bias=False)
          (1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (global_context): Sequential(
          (0): Linear(in_features=768, out_features=384, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=384, out_features=768, bias=True)
          (3): Sigmoid()
        )
        (final_refinement): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=768, out_features=768, bias=True)
          (4): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (gated_enhancement): GatedModalityEnhancement(
        (rgb_gating): ModalityGatingUnit(
          (cross_modal_attention): CrossModalAttentionGate(
            (q_proj): Linear(in_features=768, out_features=768, bias=False)
            (k_proj): Linear(in_features=768, out_features=768, bias=False)
            (v_proj): Linear(in_features=768, out_features=768, bias=False)
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (channel_gate): Sequential(
            (0): Linear(in_features=768, out_features=192, bias=True)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=192, out_features=768, bias=True)
            (3): Sigmoid()
          )
          (spatial_gate): Sequential(
            (0): Linear(in_features=1536, out_features=768, bias=True)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=768, out_features=1, bias=True)
            (3): Sigmoid()
          )
          (feature_fusion): Sequential(
            (0): Linear(in_features=1536, out_features=1536, bias=True)
            (1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
            (2): ReLU(inplace=True)
            (3): Linear(in_features=1536, out_features=768, bias=True)
            (4): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (adaptive_weight): Sequential(
            (0): Linear(in_features=1536, out_features=384, bias=True)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=384, out_features=2, bias=True)
            (3): Softmax(dim=-1)
          )
        )
        (nir_gating): ModalityGatingUnit(
          (cross_modal_attention): CrossModalAttentionGate(
            (q_proj): Linear(in_features=768, out_features=768, bias=False)
            (k_proj): Linear(in_features=768, out_features=768, bias=False)
            (v_proj): Linear(in_features=768, out_features=768, bias=False)
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (channel_gate): Sequential(
            (0): Linear(in_features=768, out_features=192, bias=True)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=192, out_features=768, bias=True)
            (3): Sigmoid()
          )
          (spatial_gate): Sequential(
            (0): Linear(in_features=1536, out_features=768, bias=True)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=768, out_features=1, bias=True)
            (3): Sigmoid()
          )
          (feature_fusion): Sequential(
            (0): Linear(in_features=1536, out_features=1536, bias=True)
            (1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
            (2): ReLU(inplace=True)
            (3): Linear(in_features=1536, out_features=768, bias=True)
            (4): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (adaptive_weight): Sequential(
            (0): Linear(in_features=1536, out_features=384, bias=True)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=384, out_features=2, bias=True)
            (3): Softmax(dim=-1)
          )
        )
        (tir_gating): ModalityGatingUnit(
          (cross_modal_attention): CrossModalAttentionGate(
            (q_proj): Linear(in_features=768, out_features=768, bias=False)
            (k_proj): Linear(in_features=768, out_features=768, bias=False)
            (v_proj): Linear(in_features=768, out_features=768, bias=False)
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (channel_gate): Sequential(
            (0): Linear(in_features=768, out_features=192, bias=True)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=192, out_features=768, bias=True)
            (3): Sigmoid()
          )
          (spatial_gate): Sequential(
            (0): Linear(in_features=1536, out_features=768, bias=True)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=768, out_features=1, bias=True)
            (3): Sigmoid()
          )
          (feature_fusion): Sequential(
            (0): Linear(in_features=1536, out_features=1536, bias=True)
            (1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
            (2): ReLU(inplace=True)
            (3): Linear(in_features=1536, out_features=768, bias=True)
            (4): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (adaptive_weight): Sequential(
            (0): Linear(in_features=1536, out_features=384, bias=True)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=384, out_features=2, bias=True)
            (3): Softmax(dim=-1)
          )
        )
        (global_coordination): GlobalCoordinationGate(
          (interaction_net): Sequential(
            (0): Linear(in_features=2304, out_features=1536, bias=True)
            (1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
            (2): ReLU(inplace=True)
            (3): Linear(in_features=1536, out_features=768, bias=True)
            (4): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (balance_net): Sequential(
            (0): Linear(in_features=4608, out_features=768, bias=True)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=768, out_features=3, bias=True)
            (3): Softmax(dim=-1)
          )
          (global_gate): Sequential(
            (0): Linear(in_features=768, out_features=192, bias=True)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=192, out_features=1, bias=True)
            (3): Sigmoid()
          )
        )
      )
    )
  )
  (pool): AdaptiveAvgPool1d(output_size=1)
  (rgb_reduce): Sequential(
    (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (1): Linear(in_features=1024, out_features=512, bias=True)
    (2): QuickGELU()
  )
  (nir_reduce): Sequential(
    (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (1): Linear(in_features=1024, out_features=512, bias=True)
    (2): QuickGELU()
  )
  (tir_reduce): Sequential(
    (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (1): Linear(in_features=1024, out_features=512, bias=True)
    (2): QuickGELU()
  )
  (generalFusion): GeneralFusion(
    (r): MultiheadAttention(
      (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
    )
    (n): MultiheadAttention(
      (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
    )
    (t): MultiheadAttention(
      (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
    )
    (rn): MultiheadAttention(
      (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
    )
    (rt): MultiheadAttention(
      (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
    )
    (nt): MultiheadAttention(
      (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
    )
    (rnt): MultiheadAttention(
      (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
    )
    (moe): MoM(
      (experts): ModuleList(
        (0): ExpertHead(
          (expertHead): ModuleList(
            (0): Expert(
              (mlp): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): QuickGELU()
                (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Expert(
              (mlp): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): QuickGELU()
                (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): Expert(
              (mlp): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): QuickGELU()
                (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): Expert(
              (mlp): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): QuickGELU()
                (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): Expert(
              (mlp): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): QuickGELU()
                (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (5): Expert(
              (mlp): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): QuickGELU()
                (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (6): Expert(
              (mlp): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): QuickGELU()
                (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
        )
        (1): ExpertHead(
          (expertHead): ModuleList(
            (0): Expert(
              (mlp): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): QuickGELU()
                (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Expert(
              (mlp): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): QuickGELU()
                (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): Expert(
              (mlp): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): QuickGELU()
                (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): Expert(
              (mlp): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): QuickGELU()
                (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): Expert(
              (mlp): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): QuickGELU()
                (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (5): Expert(
              (mlp): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): QuickGELU()
                (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (6): Expert(
              (mlp): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): QuickGELU()
                (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
        )
        (2): ExpertHead(
          (expertHead): ModuleList(
            (0): Expert(
              (mlp): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): QuickGELU()
                (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Expert(
              (mlp): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): QuickGELU()
                (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): Expert(
              (mlp): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): QuickGELU()
                (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): Expert(
              (mlp): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): QuickGELU()
                (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): Expert(
              (mlp): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): QuickGELU()
                (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (5): Expert(
              (mlp): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): QuickGELU()
                (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (6): Expert(
              (mlp): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): QuickGELU()
                (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
        )
        (3): ExpertHead(
          (expertHead): ModuleList(
            (0): Expert(
              (mlp): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): QuickGELU()
                (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Expert(
              (mlp): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): QuickGELU()
                (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): Expert(
              (mlp): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): QuickGELU()
                (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): Expert(
              (mlp): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): QuickGELU()
                (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): Expert(
              (mlp): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): QuickGELU()
                (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (5): Expert(
              (mlp): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): QuickGELU()
                (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (6): Expert(
              (mlp): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): QuickGELU()
                (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
        )
        (4): ExpertHead(
          (expertHead): ModuleList(
            (0): Expert(
              (mlp): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): QuickGELU()
                (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Expert(
              (mlp): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): QuickGELU()
                (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): Expert(
              (mlp): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): QuickGELU()
                (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): Expert(
              (mlp): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): QuickGELU()
                (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): Expert(
              (mlp): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): QuickGELU()
                (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (5): Expert(
              (mlp): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): QuickGELU()
                (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (6): Expert(
              (mlp): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): QuickGELU()
                (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
        )
        (5): ExpertHead(
          (expertHead): ModuleList(
            (0): Expert(
              (mlp): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): QuickGELU()
                (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Expert(
              (mlp): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): QuickGELU()
                (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): Expert(
              (mlp): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): QuickGELU()
                (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): Expert(
              (mlp): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): QuickGELU()
                (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): Expert(
              (mlp): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): QuickGELU()
                (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (5): Expert(
              (mlp): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): QuickGELU()
                (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (6): Expert(
              (mlp): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): QuickGELU()
                (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
        )
        (6): ExpertHead(
          (expertHead): ModuleList(
            (0): Expert(
              (mlp): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): QuickGELU()
                (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Expert(
              (mlp): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): QuickGELU()
                (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): Expert(
              (mlp): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): QuickGELU()
                (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): Expert(
              (mlp): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): QuickGELU()
                (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): Expert(
              (mlp): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): QuickGELU()
                (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (5): Expert(
              (mlp): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): QuickGELU()
                (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (6): Expert(
              (mlp): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): QuickGELU()
                (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
        )
        (7): ExpertHead(
          (expertHead): ModuleList(
            (0): Expert(
              (mlp): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): QuickGELU()
                (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Expert(
              (mlp): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): QuickGELU()
                (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): Expert(
              (mlp): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): QuickGELU()
                (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): Expert(
              (mlp): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): QuickGELU()
                (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): Expert(
              (mlp): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): QuickGELU()
                (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (5): Expert(
              (mlp): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): QuickGELU()
                (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (6): Expert(
              (mlp): Sequential(
                (0): Linear(in_features=64, out_features=64, bias=True)
                (1): QuickGELU()
                (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
        )
      )
      (gating_network): GatingNetwork(
        (gate): CrossAttention(
          (linear_re): Sequential(
            (0): Linear(in_features=3584, out_features=512, bias=True)
            (1): QuickGELU()
            (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (q_): Linear(in_features=512, out_features=512, bias=False)
          (k_): Linear(in_features=512, out_features=512, bias=False)
        )
      )
    )
    (multimodal_token_se): MultiModalTokenSE(
      (rgb_aggregator): Sequential(
        (0): Linear(in_features=128, out_features=32, bias=True)
        (1): ReLU(inplace=True)
        (2): Linear(in_features=32, out_features=128, bias=True)
        (3): Sigmoid()
      )
      (nir_aggregator): Sequential(
        (0): Linear(in_features=128, out_features=32, bias=True)
        (1): ReLU(inplace=True)
        (2): Linear(in_features=32, out_features=128, bias=True)
        (3): Sigmoid()
      )
      (tir_aggregator): Sequential(
        (0): Linear(in_features=128, out_features=32, bias=True)
        (1): ReLU(inplace=True)
        (2): Linear(in_features=32, out_features=128, bias=True)
        (3): Sigmoid()
      )
      (adaptive_weighting): AdaptiveWeighting(
        (weight_net): Sequential(
          (0): Linear(in_features=384, out_features=128, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=128, out_features=384, bias=True)
          (3): Softmax(dim=-1)
        )
      )
      (global_context_net): Sequential(
        (0): Linear(in_features=384, out_features=128, bias=True)
        (1): ReLU(inplace=True)
        (2): Linear(in_features=128, out_features=128, bias=True)
        (3): Sigmoid()
      )
      (modal_balance): Sequential(
        (0): Linear(in_features=3, out_features=8, bias=True)
        (1): ReLU(inplace=True)
        (2): Linear(in_features=8, out_features=3, bias=True)
        (3): Softmax(dim=-1)
      )
      (enhancement_net): Sequential(
        (0): Linear(in_features=384, out_features=128, bias=True)
        (1): ReLU(inplace=True)
        (2): Linear(in_features=128, out_features=128, bias=True)
        (3): Sigmoid()
      )
    )
    (feature_diversifiers): ModuleList(
      (0): FeatureDiversifier(
        (diversify_net): Sequential(
          (0): Linear(in_features=512, out_features=512, bias=True)
          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (2): ReLU()
          (3): Linear(in_features=512, out_features=512, bias=True)
        )
      )
      (1): FeatureDiversifier(
        (diversify_net): Sequential(
          (0): Linear(in_features=512, out_features=512, bias=True)
          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (2): ReLU()
          (3): Linear(in_features=512, out_features=512, bias=True)
        )
      )
      (2): FeatureDiversifier(
        (diversify_net): Sequential(
          (0): Linear(in_features=512, out_features=512, bias=True)
          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (2): ReLU()
          (3): Linear(in_features=512, out_features=512, bias=True)
        )
      )
      (3): FeatureDiversifier(
        (diversify_net): Sequential(
          (0): Linear(in_features=512, out_features=512, bias=True)
          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (2): ReLU()
          (3): Linear(in_features=512, out_features=512, bias=True)
        )
      )
      (4): FeatureDiversifier(
        (diversify_net): Sequential(
          (0): Linear(in_features=512, out_features=512, bias=True)
          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (2): ReLU()
          (3): Linear(in_features=512, out_features=512, bias=True)
        )
      )
      (5): FeatureDiversifier(
        (diversify_net): Sequential(
          (0): Linear(in_features=512, out_features=512, bias=True)
          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (2): ReLU()
          (3): Linear(in_features=512, out_features=512, bias=True)
        )
      )
      (6): FeatureDiversifier(
        (diversify_net): Sequential(
          (0): Linear(in_features=512, out_features=512, bias=True)
          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (2): ReLU()
          (3): Linear(in_features=512, out_features=512, bias=True)
        )
      )
    )
    (deformselect): DAttentionBaseline(
      (conv_offset): Sequential(
        (0): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1))
        (1): GELU(approximate='none')
        (2): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), groups=512)
        (3): GELU(approximate='none')
        (4): Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (proj_q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
      (proj_k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
      (proj_v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
      (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
      (proj_drop): Dropout(p=0.0, inplace=False)
      (attn_drop): Dropout(p=0.0, inplace=False)
    )
  )
  (classifier_moe): Linear(in_features=3584, out_features=50, bias=False)
  (bottleneck_moe): BatchNorm1d(3584, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (classifier_r): Linear(in_features=512, out_features=50, bias=False)
  (bottleneck_r): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (classifier_n): Linear(in_features=512, out_features=50, bias=False)
  (bottleneck_n): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (classifier_t): Linear(in_features=512, out_features=50, bias=False)
  (bottleneck_t): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
)
2025-05-27 22:10:24,611 DeMo INFO: number of parameters:221.230187
using soft triplet loss for training
label smooth on, numclasses: 50
2025-05-27 22:10:24,722 DeMo.train INFO: start training
diversityweight: 6.0
/home/ma1/anaconda3/envs/DeMo/lib/python3.8/site-packages/timm/models/helpers.py:7: FutureWarning: Importing from timm.models.helpers is deprecated, please import via timm.models
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.models", FutureWarning)
/home/ma1/anaconda3/envs/DeMo/lib/python3.8/site-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.models", FutureWarning)
/home/ma1/anaconda3/envs/DeMo/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
/home/ma1/work/demorelated/DeMo/modeling/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
/home/ma1/anaconda3/envs/DeMo/lib/python3.8/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/ma1/anaconda3/envs/DeMo/lib/python3.8/site-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
2025-05-27 22:10:48,222 DeMo.train INFO: Epoch[1] Iteration[10/129] Loss: 11.848, Acc: 0.017, Base Lr: 9.80e-05
2025-05-27 22:10:55,594 DeMo.train INFO: Epoch[1] Iteration[20/129] Loss: 10.084, Acc: 0.045, Base Lr: 9.80e-05
2025-05-27 22:11:03,057 DeMo.train INFO: Epoch[1] Iteration[30/129] Loss: 9.314, Acc: 0.093, Base Lr: 9.80e-05
2025-05-27 22:11:10,472 DeMo.train INFO: Epoch[1] Iteration[40/129] Loss: 8.831, Acc: 0.129, Base Lr: 9.80e-05
2025-05-27 22:11:17,871 DeMo.train INFO: Epoch[1] Iteration[50/129] Loss: 8.514, Acc: 0.154, Base Lr: 9.80e-05
2025-05-27 22:11:25,302 DeMo.train INFO: Epoch[1] Iteration[60/129] Loss: 8.265, Acc: 0.179, Base Lr: 9.80e-05
2025-05-27 22:11:32,697 DeMo.train INFO: Epoch[1] Iteration[70/129] Loss: 8.063, Acc: 0.202, Base Lr: 9.80e-05
2025-05-27 22:11:40,101 DeMo.train INFO: Epoch[1] Iteration[80/129] Loss: 7.844, Acc: 0.226, Base Lr: 9.80e-05
2025-05-27 22:11:47,516 DeMo.train INFO: Epoch[1] Iteration[90/129] Loss: 7.703, Acc: 0.245, Base Lr: 9.80e-05
2025-05-27 22:11:54,917 DeMo.train INFO: Epoch[1] Iteration[100/129] Loss: 7.546, Acc: 0.253, Base Lr: 9.80e-05
2025-05-27 22:12:02,295 DeMo.train INFO: Epoch[1] Iteration[110/129] Loss: 7.378, Acc: 0.272, Base Lr: 9.80e-05
2025-05-27 22:12:09,682 DeMo.train INFO: Epoch[1] Iteration[120/129] Loss: 7.209, Acc: 0.282, Base Lr: 9.80e-05
2025-05-27 22:12:14,939 DeMo.train INFO: Epoch 1 done. Time per batch: 0.858[s] Speed: 74.6[samples/s]
2025-05-27 22:12:14,943 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-05-27 22:12:14,943 DeMo.train INFO: Current is the ori feature testing!
2025-05-27 22:12:14,944 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
The test feature is normalized
=> Computing DistMat with euclidean_distance (before reranking)
=> Results before reranking:
mAP: 0.5533
CMC curve: Rank-1: 0.7924, Rank-5: 0.8251, Rank-10: 0.8478
=> Enter reranking
=> Results after reranking:
mAP: 0.5636
CMC curve: Rank-1: 0.7907, Rank-5: 0.8000, Rank-10: 0.8082
=> Improvement:
mAP improvement: 0.0103 (+1.86%)
Rank-1 improvement: -0.0017 (-0.22%)
2025-05-27 22:15:20,514 DeMo.train INFO: Validation Results - Epoch: 1
2025-05-27 22:15:20,515 DeMo.train INFO: mAP: 56.4%
2025-05-27 22:15:20,515 DeMo.train INFO: CMC curve, Rank-1  :79.1%
2025-05-27 22:15:20,515 DeMo.train INFO: CMC curve, Rank-5  :80.0%
2025-05-27 22:15:20,515 DeMo.train INFO: CMC curve, Rank-10 :80.8%
2025-05-27 22:15:20,515 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-05-27 22:15:20,523 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-05-27 22:15:20,523 DeMo.train INFO: Current is the moe feature testing!
2025-05-27 22:15:20,523 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/home/ma1/work/demorelated/DeMo/utils/reranking.py:40: UserWarning: This overload of addmm_ is deprecated:
	addmm_(Number beta, Number alpha, Tensor mat1, Tensor mat2)
Consider using one of the following signatures instead:
	addmm_(Tensor mat1, Tensor mat2, *, Number beta, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1420.)
  distmat.addmm_(1, -2, feat, feat.t())
The test feature is normalized
=> Computing DistMat with euclidean_distance (before reranking)
=> Results before reranking:
mAP: 0.6099
CMC curve: Rank-1: 0.8169, Rank-5: 0.8420, Rank-10: 0.8606
=> Enter reranking
=> Results after reranking:
mAP: 0.6236
CMC curve: Rank-1: 0.8437, Rank-5: 0.8531, Rank-10: 0.8618
=> Improvement:
mAP improvement: 0.0137 (+2.24%)
Rank-1 improvement: 0.0268 (+3.28%)
2025-05-27 22:18:21,020 DeMo.train INFO: Validation Results - Epoch: 1
2025-05-27 22:18:21,021 DeMo.train INFO: mAP: 62.4%
2025-05-27 22:18:21,021 DeMo.train INFO: CMC curve, Rank-1  :84.4%
2025-05-27 22:18:21,021 DeMo.train INFO: CMC curve, Rank-5  :85.3%
2025-05-27 22:18:21,021 DeMo.train INFO: CMC curve, Rank-10 :86.2%
2025-05-27 22:18:21,021 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-05-27 22:18:22,449 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-05-27 22:18:22,450 DeMo.train INFO: Current is the [moe,ori] feature testing!
2025-05-27 22:18:22,450 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
The test feature is normalized
=> Computing DistMat with euclidean_distance (before reranking)
=> Results before reranking:
mAP: 0.6156
CMC curve: Rank-1: 0.8262, Rank-5: 0.8466, Rank-10: 0.8636
=> Enter reranking
=> Results after reranking:
mAP: 0.6244
CMC curve: Rank-1: 0.8414, Rank-5: 0.8478, Rank-10: 0.8554
=> Improvement:
mAP improvement: 0.0088 (+1.43%)
Rank-1 improvement: 0.0152 (+1.83%)
2025-05-27 22:21:24,061 DeMo.train INFO: Validation Results - Epoch: 1
2025-05-27 22:21:24,062 DeMo.train INFO: mAP: 62.4%
2025-05-27 22:21:24,062 DeMo.train INFO: CMC curve, Rank-1  :84.1%
2025-05-27 22:21:24,062 DeMo.train INFO: CMC curve, Rank-5  :84.8%
2025-05-27 22:21:24,062 DeMo.train INFO: CMC curve, Rank-10 :85.5%
2025-05-27 22:21:24,062 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-05-27 22:21:32,231 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-05-27 22:21:32,231 DeMo.train INFO: Best mAP: 62.4%
2025-05-27 22:21:32,231 DeMo.train INFO: Best Rank-1: 84.1%
2025-05-27 22:21:32,231 DeMo.train INFO: Best Rank-5: 84.8%
2025-05-27 22:21:32,231 DeMo.train INFO: Best Rank-10: 85.5%
2025-05-27 22:21:32,231 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-05-27 22:21:44,614 DeMo.train INFO: Epoch[2] Iteration[10/129] Loss: 5.667, Acc: 0.311, Base Lr: 1.61e-04
2025-05-27 22:21:52,047 DeMo.train INFO: Epoch[2] Iteration[20/129] Loss: 5.851, Acc: 0.302, Base Lr: 1.61e-04
2025-05-27 22:21:59,457 DeMo.train INFO: Epoch[2] Iteration[30/129] Loss: 5.917, Acc: 0.348, Base Lr: 1.61e-04
2025-05-27 22:22:06,967 DeMo.train INFO: Epoch[2] Iteration[40/129] Loss: 5.831, Acc: 0.336, Base Lr: 1.61e-04
2025-05-27 22:22:14,377 DeMo.train INFO: Epoch[2] Iteration[50/129] Loss: 5.731, Acc: 0.314, Base Lr: 1.61e-04
2025-05-27 22:22:21,754 DeMo.train INFO: Epoch[2] Iteration[60/129] Loss: 5.792, Acc: 0.329, Base Lr: 1.61e-04
2025-05-27 22:22:29,151 DeMo.train INFO: Epoch[2] Iteration[70/129] Loss: 5.738, Acc: 0.326, Base Lr: 1.61e-04
2025-05-27 22:22:36,552 DeMo.train INFO: Epoch[2] Iteration[80/129] Loss: 5.630, Acc: 0.340, Base Lr: 1.61e-04
2025-05-27 22:22:43,865 DeMo.train INFO: Epoch[2] Iteration[90/129] Loss: 5.525, Acc: 0.353, Base Lr: 1.61e-04
2025-05-27 22:22:51,261 DeMo.train INFO: Epoch[2] Iteration[100/129] Loss: 5.352, Acc: 0.360, Base Lr: 1.61e-04
2025-05-27 22:22:58,646 DeMo.train INFO: Epoch[2] Iteration[110/129] Loss: 5.287, Acc: 0.373, Base Lr: 1.61e-04
2025-05-27 22:23:06,037 DeMo.train INFO: Epoch[2] Iteration[120/129] Loss: 5.152, Acc: 0.398, Base Lr: 1.61e-04
2025-05-27 22:23:11,332 DeMo.train INFO: Epoch 2 done. Time per batch: 0.780[s] Speed: 82.0[samples/s]
2025-05-27 22:23:11,348 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-05-27 22:23:11,349 DeMo.train INFO: Current is the ori feature testing!
2025-05-27 22:23:11,349 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
The test feature is normalized
=> Computing DistMat with euclidean_distance (before reranking)
=> Results before reranking:
mAP: 0.6000
CMC curve: Rank-1: 0.7965, Rank-5: 0.8204, Rank-10: 0.8356
=> Enter reranking
=> Results after reranking:
mAP: 0.6072
CMC curve: Rank-1: 0.8099, Rank-5: 0.8227, Rank-10: 0.8303
=> Improvement:
mAP improvement: 0.0072 (+1.20%)
Rank-1 improvement: 0.0134 (+1.68%)
2025-05-27 22:26:10,714 DeMo.train INFO: Validation Results - Epoch: 2
2025-05-27 22:26:10,714 DeMo.train INFO: mAP: 60.7%
2025-05-27 22:26:10,715 DeMo.train INFO: CMC curve, Rank-1  :81.0%
2025-05-27 22:26:10,715 DeMo.train INFO: CMC curve, Rank-5  :82.3%
2025-05-27 22:26:10,715 DeMo.train INFO: CMC curve, Rank-10 :83.0%
2025-05-27 22:26:10,715 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-05-27 22:26:11,213 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-05-27 22:26:11,214 DeMo.train INFO: Current is the moe feature testing!
2025-05-27 22:26:11,214 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
The test feature is normalized
=> Computing DistMat with euclidean_distance (before reranking)
=> Results before reranking:
mAP: 0.6106
CMC curve: Rank-1: 0.8058, Rank-5: 0.8362, Rank-10: 0.8525
=> Enter reranking
=> Results after reranking:
mAP: 0.6169
CMC curve: Rank-1: 0.8268, Rank-5: 0.8344, Rank-10: 0.8397
=> Improvement:
mAP improvement: 0.0063 (+1.03%)
Rank-1 improvement: 0.0210 (+2.60%)
2025-05-27 22:29:10,695 DeMo.train INFO: Validation Results - Epoch: 2
2025-05-27 22:29:10,695 DeMo.train INFO: mAP: 61.7%
2025-05-27 22:29:10,695 DeMo.train INFO: CMC curve, Rank-1  :82.7%
2025-05-27 22:29:10,695 DeMo.train INFO: CMC curve, Rank-5  :83.4%
2025-05-27 22:29:10,695 DeMo.train INFO: CMC curve, Rank-10 :84.0%
2025-05-27 22:29:10,695 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-05-27 22:29:11,820 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-05-27 22:29:11,820 DeMo.train INFO: Current is the [moe,ori] feature testing!
2025-05-27 22:29:11,820 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
The test feature is normalized
=> Computing DistMat with euclidean_distance (before reranking)
=> Results before reranking:
mAP: 0.6210
CMC curve: Rank-1: 0.8105, Rank-5: 0.8338, Rank-10: 0.8519
=> Enter reranking
=> Results after reranking:
mAP: 0.6308
CMC curve: Rank-1: 0.8292, Rank-5: 0.8408, Rank-10: 0.8513
=> Improvement:
mAP improvement: 0.0099 (+1.59%)
Rank-1 improvement: 0.0187 (+2.30%)
2025-05-27 22:32:13,260 DeMo.train INFO: Validation Results - Epoch: 2
2025-05-27 22:32:13,260 DeMo.train INFO: mAP: 63.1%
2025-05-27 22:32:13,260 DeMo.train INFO: CMC curve, Rank-1  :82.9%
2025-05-27 22:32:13,260 DeMo.train INFO: CMC curve, Rank-5  :84.1%
2025-05-27 22:32:13,261 DeMo.train INFO: CMC curve, Rank-10 :85.1%
2025-05-27 22:32:13,261 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-05-27 22:32:21,629 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-05-27 22:32:21,629 DeMo.train INFO: Best mAP: 63.1%
2025-05-27 22:32:21,629 DeMo.train INFO: Best Rank-1: 82.9%
2025-05-27 22:32:21,629 DeMo.train INFO: Best Rank-5: 84.1%
2025-05-27 22:32:21,629 DeMo.train INFO: Best Rank-10: 85.1%
2025-05-27 22:32:21,629 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-05-27 22:32:32,079 DeMo.train INFO: Epoch[3] Iteration[10/129] Loss: 5.125, Acc: 0.483, Base Lr: 2.24e-04
2025-05-27 22:32:39,457 DeMo.train INFO: Epoch[3] Iteration[20/129] Loss: 4.688, Acc: 0.478, Base Lr: 2.24e-04
2025-05-27 22:32:46,813 DeMo.train INFO: Epoch[3] Iteration[30/129] Loss: 4.273, Acc: 0.541, Base Lr: 2.24e-04
2025-05-27 22:32:54,178 DeMo.train INFO: Epoch[3] Iteration[40/129] Loss: 3.970, Acc: 0.516, Base Lr: 2.24e-04
2025-05-27 22:33:01,561 DeMo.train INFO: Epoch[3] Iteration[50/129] Loss: 3.773, Acc: 0.516, Base Lr: 2.24e-04
2025-05-27 22:33:08,907 DeMo.train INFO: Epoch[3] Iteration[60/129] Loss: 3.655, Acc: 0.529, Base Lr: 2.24e-04
2025-05-27 22:33:16,233 DeMo.train INFO: Epoch[3] Iteration[70/129] Loss: 3.543, Acc: 0.555, Base Lr: 2.24e-04
2025-05-27 22:33:23,554 DeMo.train INFO: Epoch[3] Iteration[80/129] Loss: 3.458, Acc: 0.583, Base Lr: 2.24e-04
2025-05-27 22:33:30,897 DeMo.train INFO: Epoch[3] Iteration[90/129] Loss: 3.475, Acc: 0.587, Base Lr: 2.24e-04
2025-05-27 22:33:38,274 DeMo.train INFO: Epoch[3] Iteration[100/129] Loss: 3.450, Acc: 0.603, Base Lr: 2.24e-04
2025-05-27 22:33:45,839 DeMo.train INFO: Epoch[3] Iteration[110/129] Loss: 3.369, Acc: 0.612, Base Lr: 2.24e-04
2025-05-27 22:33:53,215 DeMo.train INFO: Epoch[3] Iteration[120/129] Loss: 3.269, Acc: 0.624, Base Lr: 2.24e-04
2025-05-27 22:33:59,234 DeMo.train INFO: Epoch 3 done. Time per batch: 0.763[s] Speed: 83.9[samples/s]
2025-05-27 22:33:59,246 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-05-27 22:33:59,246 DeMo.train INFO: Current is the ori feature testing!
2025-05-27 22:33:59,246 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
The test feature is normalized
=> Computing DistMat with euclidean_distance (before reranking)
=> Results before reranking:
mAP: 0.6679
CMC curve: Rank-1: 0.8227, Rank-5: 0.8490, Rank-10: 0.8671
=> Enter reranking
=> Results after reranking:
mAP: 0.6740
CMC curve: Rank-1: 0.8257, Rank-5: 0.8327, Rank-10: 0.8414
=> Improvement:
mAP improvement: 0.0062 (+0.93%)
Rank-1 improvement: 0.0029 (+0.35%)
2025-05-27 22:36:59,593 DeMo.train INFO: Validation Results - Epoch: 3
2025-05-27 22:36:59,593 DeMo.train INFO: mAP: 67.4%
2025-05-27 22:36:59,594 DeMo.train INFO: CMC curve, Rank-1  :82.6%
2025-05-27 22:36:59,594 DeMo.train INFO: CMC curve, Rank-5  :83.3%
2025-05-27 22:36:59,594 DeMo.train INFO: CMC curve, Rank-10 :84.1%
2025-05-27 22:36:59,594 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-05-27 22:37:00,339 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-05-27 22:37:00,340 DeMo.train INFO: Current is the moe feature testing!
2025-05-27 22:37:00,340 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
The test feature is normalized
=> Computing DistMat with euclidean_distance (before reranking)
=> Results before reranking:
mAP: 0.6719
CMC curve: Rank-1: 0.8315, Rank-5: 0.8595, Rank-10: 0.8723
=> Enter reranking
=> Results after reranking:
mAP: 0.6787
CMC curve: Rank-1: 0.8321, Rank-5: 0.8420, Rank-10: 0.8496
=> Improvement:
mAP improvement: 0.0068 (+1.02%)
Rank-1 improvement: 0.0006 (+0.07%)
2025-05-27 22:40:01,978 DeMo.train INFO: Validation Results - Epoch: 3
2025-05-27 22:40:01,978 DeMo.train INFO: mAP: 67.9%
2025-05-27 22:40:01,978 DeMo.train INFO: CMC curve, Rank-1  :83.2%
2025-05-27 22:40:01,979 DeMo.train INFO: CMC curve, Rank-5  :84.2%
2025-05-27 22:40:01,979 DeMo.train INFO: CMC curve, Rank-10 :85.0%
2025-05-27 22:40:01,979 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-05-27 22:40:03,019 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-05-27 22:40:03,019 DeMo.train INFO: Current is the [moe,ori] feature testing!
2025-05-27 22:40:03,019 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
